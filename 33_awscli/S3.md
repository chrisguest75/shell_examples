# S3

Demonstrate how to use the `awscli` with S3  

## Reason

S3 (Simple Storage Service) is a web-based object storage service provided by Amazon Web Services (AWS). It is designed to store and retrieve any amount of data from anywhere on the web. S3 offers a scalable and highly durable platform that enables users to store and retrieve data from any location, using a simple web services interface.  

S3 provides a range of storage classes that allow users to choose the type of storage that best suits their needs based on factors such as access frequency, durability, and cost. S3 also provides features like access control, encryption, and versioning to ensure the security and integrity of stored data.  

S3 is widely used for storing and retrieving data for a variety of applications, including backup and disaster recovery, big data analytics, content distribution, and mobile and web applications.  

NOTES:

* S3 is a global resource  

TODO:

* generate crc example `aws s3api head-object --bucket chris-test-bucket-444 --key test/random.bin --checksum-mode Enabled --query ChecksumCRC32 --output text`

## Configure

```sh
export AWS_PROFILE=
export AWS_REGION=
```

## Create

```sh
# create a bucket
aws s3 mb s3://chris-test-bucket-444
```

## Listing buckets and metadata

```sh
# list buckets in the account
aws s3 ls

aws s3api list-buckets | jq '.["Buckets"][].Name' --raw-output 

# get tags 
aws s3api list-buckets | jq '.["Buckets"][].Name' --raw-output | while read in; do aws s3api get-bucket-tagging --bucket $in; done

# get audit logging for each bucket.
aws s3api list-buckets | jq '.["Buckets"][].Name' --raw-output | while read in; do aws s3api get-bucket-logging --bucket $in; done

# listing buckets with logging.
aws s3api list-buckets | jq '.["Buckets"][].Name' --raw-output | while read bucket; do _BUCKET_LOGGING=$(aws s3api get-bucket-logging --bucket $bucket | jq -c .) 
if [ -z "$_BUCKET_LOGGING" ]; then
    echo '{"bucket": "'$bucket'", "logging": "N/A"}' | jq -c . 
else
    echo "$_BUCKET_LOGGING" | jq --arg bucket $bucket -c '{bucket: $bucket, logging: ("s3://" + .LoggingEnabled.TargetBucket + "/" + .LoggingEnabled.TargetPrefix)}'
fi; done
```

## Listing Contents

```sh
# list contents of bucket 
aws --profile myprofile s3 ls s3://bucket_name

# with summary and human readable file sizes
aws s3 ls s3://chris-test-bucket-444  --recursive --human-readable --summarize
```

## Copying

```sh
# Copy files from s3 into s3 subfolder
aws s3 cp "s3://file.json" "s3://bucket_name/folder/subfolder/ignition_etcd_0.json"

# copy local file to s3
aws --profile myprofile s3 cp ./fragment.json s3://bucket_name/fragment.json

# copying folders 
aws --profile myprofile s3 cp --recursive "s3://bucket/folder" ./folder

# copying folders and enabling public read access
aws --profile myprofile s3 cp --recursive "s3://bucket/folder" ./folder --acl public-read
```

## CORS

```sh
# examine the cors profile for the bucket
aws --profile myprofile s3api get-bucket-cors --bucket "bucket" | jq .
```

## Syncing

Syncing files can be done bi-directionally.

```sh
aws s3 sync s3://bucket_name path/to/target

# copy to public bucket and make available. 
AWS_PROFILE=myprofile aws s3 sync --acl public-read ./myfolder s3://mybucket/myfolder
```

## Presigning

Presigned URLs are temporary URLs that grant time-limited access to an object in Amazon S3 or other cloud storage services. They are generated using AWS credentials and provide limited permission to perform a specific set of operations on the object or resource.  

Presigned URLs are often used in scenarios where an application or user needs to share a resource or object without giving permanent access to the resource. For example, a website may provide a download link to a user for a file stored on Amazon S3. Rather than granting the user direct access to the object, the website can generate a presigned URL that is valid for a specific amount of time. The user can then use the presigned URL to download the file during the specified time period.  

Presigned URLs are often used for secure distribution of content, sharing of large files, and temporary access to resources for specific operations or tasks. They provide a secure and efficient way to share resources with limited permissions and help to ensure that resources are not accessed or modified beyond their intended use.  

```sh
# copy a file to a bucket
aws s3 cp ../BATCH.md s3://bucket

# expiry is in seconds
SIGNEDURL1=$(aws s3 presign bucket/BATCH.md --expires-in 1000)
echo $SIGNEDURL1
SIGNEDURL2=$(aws s3 presign bucket/BATCH.md --expires-in 1000)
echo $SIGNEDURL2
curl -v -s -o /dev/null $SIGNEDURL1
curl -v -s -o /dev/null $SIGNEDURL2
```

## Deleting

```sh
aws s3 rm s3://test-bucket/folder --recursive
```

## Validating Checksums (single files)

```sh
# generate random numbers
mkdir -p ./out

dd if=/dev/urandom of=./out/random.bin bs=1024 count=10
# check md5
md5sum ./out/random.bin > ./out/random.bin.md5
md5sum --check ./out/random.bin.md5 

# copy file to s3
aws s3 cp ./out/random.bin s3://bucket/test/random.bin

# show contents
aws s3 ls s3://bucket/test/    

# check md5 matches the etag.  
aws s3api get-object-attributes --bucket bucket --key test/random.bin --object-attributes Checksum ObjectSize ETag --output json | jq -r '.ETag'
```

## Generate S3 manifest

```sh
aws s3api list-objects --bucket mybucket --prefix testsruntimefolder/1678128187/ --query 'Contents[].{Key: Key}'
```

## Resources

* What is Amazon S3? [here](https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html)  
* AWS CLI s3 get-object [here](https://docs.aws.amazon.com/cli/latest/reference/s3api/get-object.html)  
* Does aws-cli confirm checksums when uploading files to S3, or do I need to manage that myself? [here](https://stackoverflow.com/questions/26168481/does-aws-cli-confirm-checksums-when-uploading-files-to-s3-or-do-i-need-to-manag)  
* New â€“ Additional Checksum Algorithms for Amazon S3 [here](https://aws.amazon.com/blogs/aws/new-additional-checksum-algorithms-for-amazon-s3/)
* Support S3 additional checksums in high-level S3 commands #6750 [here](https://github.com/aws/aws-cli/issues/6750)  
* Amazon S3 Inventory Reports [here](https://docs.aws.amazon.com/AmazonS3/latest/userguide/storage-inventory.html)  
